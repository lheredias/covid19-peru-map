{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peru: Two Years of COVID-19\n",
    "A very basic analysis of the impact of COVID-19 in Peru with Pandas, Geopandas and Matplotlib in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How hard has COVID-19 struck a city / country / region?\n",
    "\n",
    "One way to address this question is to take a look at the deaths, or more precisely, the excess mortality caused by the virus.\n",
    "\n",
    "In this occassion, we desire to make a very simple analysis of the effects of COVID-19 in each \"departamento\" (sort of equivalent to a U.S. state) of Peru.\n",
    "\n",
    "In order to do that, we are going to create **choropleth maps** with monthly deaths ocurred in a given month since 2020-01 for each \"departamento\" adjusted by population, and display these maps through a .gif.\n",
    "\n",
    "Now, for the sake of simplicity, we are going to work with total and not exxess deaths and assume that \"DEPARTAMENTO DOMICILIO\" stands for the place (\"departamento\") where the decease took place. In reality, \"DEPARTAMENTO DOMICILIO\" accounts for the last informed \"departamento\" of residency.\n",
    "\n",
    "We are going to work with the national deaths database of Peru, SINADEF, and the GeoJSON data of this country, available at GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "import subprocess\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset and store it in \"df\" `dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"fallecidos_sinadef.csv\",engine=\"python\",encoding='utf-8-sig',sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nº</th>\n",
       "      <th>TIPO SEGURO</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>TIEMPO EDAD</th>\n",
       "      <th>ESTADO CIVIL</th>\n",
       "      <th>NIVEL DE INSTRUCCIÓN</th>\n",
       "      <th>ETNIA</th>\n",
       "      <th>COD# UBIGEO DOMICILIO</th>\n",
       "      <th>PAIS DOMICILIO</th>\n",
       "      <th>...</th>\n",
       "      <th>DEBIDO A (CAUSA B)</th>\n",
       "      <th>CAUSA B (CIE-X)</th>\n",
       "      <th>DEBIDO A (CAUSA C)</th>\n",
       "      <th>CAUSA C (CIE-X)</th>\n",
       "      <th>DEBIDO A (CAUSA D)</th>\n",
       "      <th>CAUSA D (CIE-X)</th>\n",
       "      <th>DEBIDO A (CAUSA E)</th>\n",
       "      <th>CAUSA E (CIE-X)</th>\n",
       "      <th>DEBIDO A (CAUSA F)</th>\n",
       "      <th>CAUSA F (CIE-X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>IGNORADO</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>64</td>\n",
       "      <td>AÑOS</td>\n",
       "      <td>SOLTERO</td>\n",
       "      <td>IGNORADO</td>\n",
       "      <td>MESTIZO</td>\n",
       "      <td>92-33-24-01-01-000</td>\n",
       "      <td>PERU</td>\n",
       "      <td>...</td>\n",
       "      <td>INFARTO RECIENTE Y ANTIGUO DE MIOCARDIO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SIS</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>15</td>\n",
       "      <td>MINUTOS</td>\n",
       "      <td>SOLTERO</td>\n",
       "      <td>SUPERIOR NO UNIV. COMP.</td>\n",
       "      <td>MESTIZO</td>\n",
       "      <td>92-33-12-08-06-000</td>\n",
       "      <td>PERU</td>\n",
       "      <td>...</td>\n",
       "      <td>DIFICULTAD RESPIRATORIA DEL RECIEN NACIDO</td>\n",
       "      <td>P229</td>\n",
       "      <td>INMATURIDAD EXTREMA</td>\n",
       "      <td>P072</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ESSALUD</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>97</td>\n",
       "      <td>AÑOS</td>\n",
       "      <td>CASADO</td>\n",
       "      <td>PRIMARIA INCOMPLETA</td>\n",
       "      <td>MESTIZO</td>\n",
       "      <td>92-33-04-01-23-000</td>\n",
       "      <td>PERU</td>\n",
       "      <td>...</td>\n",
       "      <td>ENFERMEDAD RENAL</td>\n",
       "      <td>N189</td>\n",
       "      <td>ENFERMEDAD PULMONAR INTERSTICIAL DIFUSA</td>\n",
       "      <td>J849</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>IGNORADO</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>31</td>\n",
       "      <td>AÑOS</td>\n",
       "      <td>SOLTERO</td>\n",
       "      <td>IGNORADO</td>\n",
       "      <td>MESTIZO</td>\n",
       "      <td>92-33-07-06-01-000</td>\n",
       "      <td>PERU</td>\n",
       "      <td>...</td>\n",
       "      <td>EDEMA PULMONAR</td>\n",
       "      <td>J81X</td>\n",
       "      <td>EN INVESTIGACION</td>\n",
       "      <td>R99X</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>IGNORADO</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>59</td>\n",
       "      <td>AÑOS</td>\n",
       "      <td>SOLTERO</td>\n",
       "      <td>IGNORADO</td>\n",
       "      <td>MESTIZO</td>\n",
       "      <td>92-33-24-01-01-000</td>\n",
       "      <td>PERU</td>\n",
       "      <td>...</td>\n",
       "      <td>SHOCK HIPOVOLEMICO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SUCESO DE TRANSITO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "      <td>SIN REGISTRO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nº TIPO SEGURO       SEXO EDAD TIEMPO EDAD ESTADO CIVIL  \\\n",
       "0   1    IGNORADO   FEMENINO   64        AÑOS      SOLTERO   \n",
       "1   2         SIS   FEMENINO   15     MINUTOS      SOLTERO   \n",
       "2   3     ESSALUD  MASCULINO   97        AÑOS       CASADO   \n",
       "3   4    IGNORADO  MASCULINO   31        AÑOS      SOLTERO   \n",
       "4   5    IGNORADO  MASCULINO   59        AÑOS      SOLTERO   \n",
       "\n",
       "      NIVEL DE INSTRUCCIÓN    ETNIA COD# UBIGEO DOMICILIO PAIS DOMICILIO  ...  \\\n",
       "0                 IGNORADO  MESTIZO    92-33-24-01-01-000           PERU  ...   \n",
       "1  SUPERIOR NO UNIV. COMP.  MESTIZO    92-33-12-08-06-000           PERU  ...   \n",
       "2      PRIMARIA INCOMPLETA  MESTIZO    92-33-04-01-23-000           PERU  ...   \n",
       "3                 IGNORADO  MESTIZO    92-33-07-06-01-000           PERU  ...   \n",
       "4                 IGNORADO  MESTIZO    92-33-24-01-01-000           PERU  ...   \n",
       "\n",
       "                          DEBIDO A (CAUSA B) CAUSA B (CIE-X)  \\\n",
       "0    INFARTO RECIENTE Y ANTIGUO DE MIOCARDIO             NaN   \n",
       "1  DIFICULTAD RESPIRATORIA DEL RECIEN NACIDO            P229   \n",
       "2                           ENFERMEDAD RENAL            N189   \n",
       "3                             EDEMA PULMONAR            J81X   \n",
       "4                         SHOCK HIPOVOLEMICO    SIN REGISTRO   \n",
       "\n",
       "                        DEBIDO A (CAUSA C) CAUSA C (CIE-X)  \\\n",
       "0                                      NaN             NaN   \n",
       "1                      INMATURIDAD EXTREMA            P072   \n",
       "2  ENFERMEDAD PULMONAR INTERSTICIAL DIFUSA            J849   \n",
       "3                         EN INVESTIGACION            R99X   \n",
       "4                       SUCESO DE TRANSITO    SIN REGISTRO   \n",
       "\n",
       "   DEBIDO A (CAUSA D)  CAUSA D (CIE-X) DEBIDO A (CAUSA E) CAUSA E (CIE-X)  \\\n",
       "0                 NaN              NaN                NaN             NaN   \n",
       "1        SIN REGISTRO     SIN REGISTRO       SIN REGISTRO    SIN REGISTRO   \n",
       "2        SIN REGISTRO     SIN REGISTRO       SIN REGISTRO    SIN REGISTRO   \n",
       "3        SIN REGISTRO     SIN REGISTRO       SIN REGISTRO    SIN REGISTRO   \n",
       "4        SIN REGISTRO     SIN REGISTRO       SIN REGISTRO    SIN REGISTRO   \n",
       "\n",
       "  DEBIDO A (CAUSA F) CAUSA F (CIE-X)  \n",
       "0                NaN             NaN  \n",
       "1       SIN REGISTRO    SIN REGISTRO  \n",
       "2       SIN REGISTRO    SIN REGISTRO  \n",
       "3       SIN REGISTRO    SIN REGISTRO  \n",
       "4       SIN REGISTRO    SIN REGISTRO  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846732, 32)\n",
      "Index(['Nº', 'TIPO SEGURO', 'SEXO', 'EDAD', 'TIEMPO EDAD', 'ESTADO CIVIL',\n",
      "       'NIVEL DE INSTRUCCIÓN', 'ETNIA', 'COD# UBIGEO DOMICILIO',\n",
      "       'PAIS DOMICILIO', 'DEPARTAMENTO DOMICILIO', 'PROVINCIA DOMICILIO',\n",
      "       'DISTRITO DOMICILIO', 'FECHA', 'AÑO', 'MES', 'TIPO LUGAR',\n",
      "       'INSTITUCION', 'MUERTE VIOLENTA', 'NECROPSIA', 'DEBIDO A (CAUSA A)',\n",
      "       'CAUSA A (CIE-X)', 'DEBIDO A (CAUSA B)', 'CAUSA B (CIE-X)',\n",
      "       'DEBIDO A (CAUSA C)', 'CAUSA C (CIE-X)', 'DEBIDO A (CAUSA D)',\n",
      "       'CAUSA D (CIE-X)', 'DEBIDO A (CAUSA E)', 'CAUSA E (CIE-X)',\n",
      "       'DEBIDO A (CAUSA F)', 'CAUSA F (CIE-X)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are interested in \"FECHA\" `string` and \"DEPARTAMENTO DOMICILIO\" `string` . In other words, the date of the decease and where it ocurred. \n",
    "- We also want to order this dataset by date so we cretae a new column \"DATE\" `datetime` based on \"FECHA\" and apply the `sort_values` method.\n",
    "- Inspecting \"FECHA\" `string` we realise that it goes back to 2017. Since covid-19 pandemic struck Peru in March 2020, we filter the dataset on \"AÑO\" `int` >= 2020.\n",
    "- Since \"DEPARTAMENTO DOMICILIO\" `string` includes places ourside Peru, we filter the dataset on \"PAIS DOMICILIO\" `string` == \"PERU\".\n",
    "- There is an empty string in \"DEPARTAMENTO DOMICILIO\" `string` representing the unknown, so we get rid of it by applying yet another filter.\n",
    "- Now that our dataset is ordered by date we create a new column \"MES-AÑO\" `string` based of the year and month of \"FECHA\" `string`, as in, 202001, 202002, and so on.\n",
    "- We finally slice our dataset by \"DEPARTAMENTO DOMICILIO\" `string`, \"MES-AÑO\" `string` and \"SEXO\" `string`. We could have picked any other column instead of \"SEXO\" as long as it holds one entry per row, which most columns do. This is beceause we are going to group our dataset by \"MES-AÑO\" and count occurrences of the third column (deaths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'] = df['FECHA'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "df = df.sort_values(by=['DATE'], ascending=True)\n",
    "df=df[(df[\"PAIS DOMICILIO\"]==\"PERU\") & (df[\"AÑO\"].isin([2020,2021,2022]))]\n",
    "df[\"DEPARTAMENTO DOMICILIO\"] = df[\"DEPARTAMENTO DOMICILIO\"].map(str.strip)\n",
    "df=df[df[\"DEPARTAMENTO DOMICILIO\"]!=\"\"]\n",
    "df[\"MES-AÑO\"]=df[\"FECHA\"].apply(lambda x: x[:5])+df[\"FECHA\"].apply(lambda x: x[5:7])\n",
    "df=df[['DEPARTAMENTO DOMICILIO',\"MES-AÑO\",\"SEXO\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a more concise dataset we can apply two `for loop`s in order to obtain a list of dicts, where each dict represents a \"DEPARTAMENTO DOMICILIO\" and is going to be comprised of \"date\", \"deaths\" key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "max=0\n",
    "for dep in df[\"DEPARTAMENTO DOMICILIO\"].unique():\n",
    "  data={}\n",
    "  sdf=df[df[\"DEPARTAMENTO DOMICILIO\"]==dep]\n",
    "  sdf=sdf.groupby(sdf['MES-AÑO']).count().reset_index()\n",
    "  for date in df['MES-AÑO'].unique():\n",
    "    try:\n",
    "      data[date]=sdf[sdf[\"MES-AÑO\"]==date][\"SEXO\"].values[0]\n",
    "    except IndexError:\n",
    "      data[date]=0\n",
    "    if data[date]>max:\n",
    "      max=data[date]\n",
    "  result.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of dicts, we can easily convert it into a pandas dataframe object and store it in \"final_df\" `dataframe`, setting each \"DEPARTAMENTO DOMICILIO\" as an index. Then we sort this brand new dataframe by its index in alphabetical order so we can match it with the new dataset (GeoJSON) that we are going to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.DataFrame(result,index=df[\"DEPARTAMENTO DOMICILIO\"].unique()) \n",
    "final_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check this newly created dataset, we can appreciate that it contains 25 \"DEPARTAMENTO DOMICILIO\" (places where deaths have occurred) and 27 \"MES-AÑO\" (date of decease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 27)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A proper comparison of deaths in each \"departamento\" shall take into account how many people live in such \"departamento\". So, in the end, we are going to measure deaths by population.\n",
    "- In order to do that we need the population of each \"departamento\" and that can be found [here](https://es.wikipedia.org/wiki/Anexo:Departamentos_del_Perú_por_población).\n",
    "- This wikipedia dataset can be read directly with pandas `read_html` method but first we need to parse part of the url for it contains accents.\n",
    "- We finally store that population dataset in \"pop_array\" `dataframe`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"https://es.wikipedia.org/wiki/\"\n",
    "query='Anexo:Departamentos_del_Perú_por_población'\n",
    "query=urllib.parse.quote(query)\n",
    "url=base_url+query\n",
    "url\n",
    "pop_df=pd.read_html(url)[0]\n",
    "pop_array=pop_df[(\"Población\",\"Estimado 2020\")].apply(lambda x: int(x.replace(\"\\xa0\",\"\"))).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we divide each column in \"final_df\" `dataframe` by \"pop_array\" `dataframe` and replace \"final_df\"'s values. In other words, we go from \"deaths\" to \"deaths adjusted by population\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in final_df.columns:\n",
    "  final_df[date]=final_df[date]/pop_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to import the GeoJSON data for every \"departamento\" or state of Peru and store it in \"df_peru\" `dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peru = gpd.read_file('https://raw.githubusercontent.com/juaneladio/peru-geojson/master/peru_departamental_simple.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a new column \"coords\" which is going to be used to label each \"departamento\" with its name on the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peru['coords'] = df_peru['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "df_peru['coords'] = [coords[0] for coords in df_peru['coords']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having finshed the data manipulation part, we can move onto plotting our choropleth maps.\n",
    "\n",
    "- First, we set vmin and vmax variables to store the min and max global amount of deaths.\n",
    "> If you don’t set this beforehand, Matplotlib will change the range of the choropleth each time the for loop iterates, so it will be harder to see how values have increased or decreased over time.\n",
    "- Then, we create a for loop that, for each date, appends to df_peru `dataframe` (GeoJSON data) a column of final_df `dataframe`, plots the choropleth map and then removes that column back so as not to increase the size of df_peru `dataframe` in each loop.\n",
    "- Also, in each loop, we store the plotted map inside the just created \"img\" directory with padding zeros to keep a proper order.\n",
    "\n",
    "This whole process will create a total of 27 choropleth maps (one per date) inside \"img\" directory .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 27 processed\n",
      "2 of 27 processed\n",
      "3 of 27 processed\n",
      "4 of 27 processed\n",
      "5 of 27 processed\n",
      "6 of 27 processed\n",
      "7 of 27 processed\n",
      "8 of 27 processed\n",
      "9 of 27 processed\n",
      "10 of 27 processed\n",
      "11 of 27 processed\n",
      "12 of 27 processed\n",
      "13 of 27 processed\n",
      "14 of 27 processed\n",
      "15 of 27 processed\n",
      "16 of 27 processed\n",
      "17 of 27 processed\n",
      "18 of 27 processed\n",
      "19 of 27 processed\n",
      "20 of 27 processed\n",
      "21 of 27 processed\n",
      "22 of 27 processed\n",
      "23 of 27 processed\n",
      "24 of 27 processed\n",
      "25 of 27 processed\n",
      "26 of 27 processed\n",
      "27 of 27 processed\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"img\")\n",
    "title=\"Deaths per 'departamento', adjusted by population\"\n",
    "vmin, vmax=0,final_df.max().max()\n",
    "df.columns\n",
    "i=1\n",
    "for date in final_df.columns.values:\n",
    "  df_peru[date]=final_df[date].values\n",
    "  fig, ax = plt.subplots(1, figsize=(13, 15))\n",
    "\n",
    "  df_peru.plot(column=date,cmap='cool',\n",
    "  linewidth=1, ax=ax,edgecolor='1', vmin=vmin, vmax=vmax,legend=True,\n",
    "  norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "  ax.axis(\"off\")\n",
    "  ax.set_title(title,fontsize=20)\n",
    "  for idx, row in df_peru.iterrows():\n",
    "    ax.text(row.coords[0], row.coords[1], row[\"NOMBDEP\"], \n",
    "    horizontalalignment='center', \n",
    "    bbox={'facecolor': 'white', 'alpha':0.8, 'pad': 2, 'edgecolor':'none'})\n",
    "  ax.annotate(f\"{date}\", xy=(0.2, .3), xycoords='figure fraction',\n",
    "            horizontalalignment='left', verticalalignment='bottom',\n",
    "            fontsize=30)\n",
    "  if i<10:\n",
    "    filepath = f\"img/00{i}.jpg\"\n",
    "  else:\n",
    "    filepath = f\"img/0{i}.jpg\"\n",
    "\n",
    "  chart = ax.get_figure()\n",
    "  chart.savefig(filepath, dpi=200)\n",
    "  plt.close()\n",
    "  df_peru.drop(columns=date, inplace=True)\n",
    "  print(f\"{i} of {len(final_df.columns)} processed\")\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, we make a .gif out of those 27 images and, if preferred, erase them to save disk space.\n",
    "\n",
    "Please note that in order to perform this action, you must install ImageMagick, as in `brew install imagemagick` (MacOS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "back=os.getcwd()\n",
    "os.chdir(\"img\")\n",
    "subprocess.call([\n",
    "  \"convert\", \"-delay\", \"90\", \"-loop\", \"0\", \"*.jpg\",\"output.gif\"\n",
    "])\n",
    "for file_name in glob.glob(\"*.jpg\"):\n",
    "    os.remove(file_name)\n",
    "os.chdir(back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can also create a .mp4 video instead of a .gif.\n",
    "\n",
    "Please note that in order to perform this action, you must install FFmpeg, as in `brew install ffmpeg` (MacOS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back=os.getcwd()\n",
    "os.chdir(\"img\")\n",
    "subprocess.call([\n",
    "    'ffmpeg', '-framerate', '24', '-i','%03d.jpg', '-r', '30',\"-crf\", \"0\", \"-vcodec\", \"mpeg4\", \"-vf\", \"setpts=10*PTS\",\n",
    "    'video_name.mp4'\n",
    "])\n",
    "for file_name in glob.glob(\"*.jpg\"):\n",
    "    os.remove(file_name)\n",
    "os.chdir(back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=img/output.gif>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "- https://towardsdatascience.com/how-to-make-a-gif-map-using-python-geopandas-and-matplotlib-cd8827cefbc8\n",
    "- https://stackoverflow.com/questions/38899190/geopandas-label-polygons"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e281e4b2feb3ee64f6fa3492874c01f2a4f870b6008b9faff3d647fa4da0be5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
